<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Talk is cheap. Show me the code."><title>站在2021年的这个节点上，回望过去十年深度学习的发展 | 陈浩</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">站在2021年的这个节点上，回望过去十年深度学习的发展</h1><a id="logo" href="/.">陈浩</a><p class="description">Talk is cheap. Show me the code.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/archives/"><i class="fa fa-user"> 关于</i></a><a href="/archives/"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">站在2021年的这个节点上，回望过去十年深度学习的发展</h1><div class="post-meta">2021-06-18</div><div class="post-content"><h2 id="1、历史回顾"><a href="#1、历史回顾" class="headerlink" title="1、历史回顾"></a>1、历史回顾</h2><p>深度学习的历史可以追溯到上个世纪50年代，那时的神经网络还只是个简单的全连接网络，反向传播算法和激活函数还不曾出现，由于神经网络是模拟人类神经元所提出，同时在简单的分类任务上表现出不错的性能，于是伴随着星空般的遐想，第一次深度学习的浪潮被引爆，然而这场浪潮只持续了短短10年左右的时间。</p>
<p>1969年，Marvin Minsky在著作中证明目前的神经网络本质上只是一种线性模型，甚至连异或这种简单的逻辑也无法表示，于是第一次浪潮戛然而止，进入长达20年寒冬期。</p>
<p>在这漫长的20年里，神经网络技术依旧在暗处缓慢的积累的力量，伴随着反向传播算法的成熟，激活函数的引入以及CNN等网络结构的出现，神经网络再次活跃起来。也正是在这个时期，第一个真正落地的神经网结构LeNet在贝尔实验室被提出，用于识别邮票的手写邮政编码，该网络为后来的各种网络结构提供了无数灵感。也在此时期，LSTM这个今天依然热门的网络结构被提出，然而在这欣欣向荣之中，由于传统机器学习的不断发展成熟，SVM等算法的提出，再加上当时计算机算力和数据量的约束，第二次深度学习的浪潮缓缓落幕，再次回到暗处缓慢发展。</p>
<p>以上是前两次深度学习浪潮的简单介绍，严格来说前两次浪潮并不能称之为深度学习，深度学习这个名字的提出是在2006由Geoffrey Hinton，主要是为了体现出越来越深的网络结构。现在我们将镜头转向第三次深度学习浪潮，也正是我们现在所处的这个时代。</p>
<p>一般认为此次浪潮的起点是2012的ImageNet挑战赛上AlexNet的夺冠，AlexNet的成功再次证明了深度学习的潜力和价值，也正是AlexNet的成功，使得深度学习再次流行起来。真正在社会大众中引爆深度学习热潮的毫无疑问是2016年AlphaGo与李世石的五局围棋比赛，深度学习以王者姿态出现在社会大众的面前。次年AlphaGo Zero的出现，再次彰显深度学习无与伦比的魅力。2016年的4年后也就是2020年，回望去年深度学习的发展，最有影响力的两件事当属依然是Deepmind开发的AlphaFold2在蛋白质结构预测上的成功，和OpenAI开发的全球最大预训练语言模型GPT-3的发布，不论是AlphaFold2还是GPT-3，都能给人带来无尽的想像空间。</p>
<p>好了，让我们抛开这些历史故事，和那些激动人心的时刻，回到技术本身，来看一看这十年都发生了什么。<br>深度学习的研究领域浩如烟海，如果再加上领域交叉，更会是无穷无尽。这里我们先只讨论深度学习的主赛道，同时自己相对比较熟悉的领域。</p>
<h2 id="2、计算机视觉领域"><a href="#2、计算机视觉领域" class="headerlink" title="2、计算机视觉领域"></a>2、计算机视觉领域</h2><p>让我们先从计算机视觉（CV）讲起，在各个领域中，计算机视觉是最早达成大一统的领域。在17年Google的《Attention is all you need》论文出现以前，CNN包揽了计算机视觉的每一个任务上，不论是图像分类，目标检测，还是图像分隔以及图像增强。</p>
<p>图像分类是计算机视觉最传统，也是最基础的任务之一，从第二次深度学习浪潮的LeNet到本次深度学习浪潮的AlexNet，所解决的都是图像分类的问题。LeNet（1989），AlexNet（2012），VGGNet（2014），这三个网络最大的改变是网络结构越来越深，越来越多的证明显示出堆叠卷积层的有效性，但是卷积层的堆积会遇到很多问题，AlexNet和VGGNet都给出了自己的解决方案，然而这些解决方案没能从本质上解决问题，即使是VGGNet也只有19层网络。于是时间来到2015年，当年的ImageNet竞赛上ResNet横空出世，skip-connection的提出直接使得网络的层数提升了一个数量级，ResNet横扫各大数据集。于是接下来ConV+Pool+ResNet+Dropout成为图像分类任务的标准配置。</p>
<p>目标检测也是计算机视觉里非常基础的一个任务，是目前自动驾驶的灵魂。目标检测是在图像分类的基础上发展而来的，纵观目标检测的发展史，基本可以分成两个阶段。早期的R-CNN，FastRCNN，FasterRCNN，这条路线上的两阶段模型，围绕着RCNN进行优化改进，这些算法的本质是在图像的各个可能存在物体的区域上进行图像分类，首先需要提取可能存在物体的区域，接着对这些区域使用图像分类算法求取这些区域所包含的物体，所以称之为两阶段算法。然而这些算法太慢了，网络结构也过分复杂，于是时间来到2016年，YOLO重磅登场。这个YOLO不是You only live once，而是You only look once，YOLO直接将检测问题转化为回归问题，于是目标检测不再需要使用多个网络，而是只需要将图像输入到一个网络之中，便能够得到图像中存在的所有物体及物体的位置。YOLO之后的目标检测算法如SSD也是借鉴此思路，YOLO出现之后，其进化之路一直没有停止，从YOLO1到YOLO2（YOLO9000），一直到去年放出的YOLO5，每一次YOLO新版本的发布，都会引来无数的关注。</p>
<p>计算机视觉领域经过这些年的发展，已经非常成熟，各种问题都有着近乎统一的解决方案，而效果也都十分惊艳，这几年创新性的idea越来越少。以图像增强中的超分为例，任务是将低分辨率的图像转化为高分辨率的图像，该领域从2014年SRCNN的开山之作，后面出现FSRCNN，SRGAN，VDSR，EDSR等，该领域每年顶会上相关的论文几十上百篇，然而如果细看网络结构，其实没什么突破性的创新和改进，甚至被笑称“网络连连看”。记得去年这个时候，Transformer在计算机视觉领域大热，大有取CNN而代之的势头，各种Transformer+vision出现在各大顶会上。今年Google放出的MLP工作又震惊一众从业者，让人吐槽CV是个圈，绕来绕去又回到了最初的多层感知机的全连接网络。</p>
<h2 id="3、自然语言处理领域"><a href="#3、自然语言处理领域" class="headerlink" title="3、自然语言处理领域"></a>3、自然语言处理领域</h2><p>再来讲讲自然语言处理（NLP）领域，这个领域的进展相对计算机视觉的发展要缓慢很多，在BERT出现之前处于乱战时期。如果要从这个领域抽出一条脉络的话，要属预训练的概念，预训练并非是NLP所独有的，也存在于在CV领域之中，甚至在CV领域中是比较常见的一种技术。在NLP里预训练究竟是在做什么？对于图像来说，其本身就是一堆像素编码，天然就是计算机的语言，而对于文本句子来说，究竟如何恰当的将其表示成向量或矩阵是一件非常困难的事情，最简单的思路是使用Onehot编码单词，然而Onehot编码向量太长了，同时更严重的是Onehot编码后的向量是正交的，这也就意味着Onehot编码后单词之间没有任何联系，这对于NLP来说是致命的。</p>
<p>现在我们把目光放到预训练的发展上，核心就是如何更好的编码单词，后续使用的时候只需要根据任务进行Fine-tuning即可。神经网络和自然语言处理纠缠在一起，然后迸发出耀眼的光芒，这一切的开端都要从2003年的一篇论文《A Neural Probabilistic Language Model》讲起。然而这篇论文刚放出的年代，正是神经网络式微，传统机器学习大杀四方的年代，因此这篇论文刚出来的时候并没有激起该有的火花，然而历史终究会回到正确的路上，于是十年后2013年这篇论文再次被发现，开启了神经网络处理自然语言的大时代。</p>
<p>NNLP这篇论文本身并不是为了去更好的编码单词，但其网络结构第一层全连接的设置，正是Word Embedding的思想，于是后续的预训练模型层出不穷，效果越来越好，整个领域也因此蓬勃发展。从Word2Vec一路进化到BERT，中间还有GloVe，ELMO，GPT，整体的趋势是特征提取器越来越强（从LSTM到Transformer），单向特征提取到双向特征提取，模型训练方法从CBOW（根据上下文预测当前词语），Skip-gram（根据当前词语预测上下文）到BERT的Mask（遮住部分词语来预测被遮住的部分），其实本质上BERT的Mask和CBOW并没有什么区别。站在现在的视角，回首去看BERT的实现思路，其实从技术的角度并没有特别创新性的思想。可以将BERT视为各种预训练模型的集大成者，融各加所长于一身，通过暴力美学外加海量的数据库，实现一个又一个令人瞠目结舌的成果。BERT一经推出，便汇聚了所有的视线成为焦点，自此NLP领域进入后BERT时代，不管啥任务，不论啥问题，上BERT就对了。BERT的出现也意味着NLP进入“Money is all you need“时代，对于BERT的复现，目前深度学习常用GPU的12-24G显存，很难满足BERT的需求，虽然后面也出现了ALBERT（A Lite BERT），但BERT的成功证明了一个非常深的网络再加上海量的数据是有效的，于是NLP领域模型越来越大的趋势无可阻挡。</p>
<p>BERT之后，GPT-3的出现，再次证明了大模型的潜力，接近1750亿参数的网络结构，远超之前常规网络两个数量级的提高，但是GPT-3的结果实在是太惊艳了，即使不是NLP领域的人，甚至不是做深度学习的人，可能都听说过GPT-3模型，无他，只怪GPT-3太过强大。当然GPT-3根本不是普通玩家甚至高级玩家能玩得动的，这条赛道目前只有寥寥几名顶级玩家拥有入场的资格，训练一次GPT-3所需要的费用，已经达到几百万甚至上千万美元的程度。今年GPT-3再次进化，OpenAI携DALL-E再次登场，被称之为图像版的GPT-3，效果依然爆炸般优秀，当然DALL-E不只是GPT-3的延伸，更重要的融入了对比表示学习和多模态的新技术，更具备深厚的潜力。</p>
<p>当然了提到NLP必然离不开的一个模型当属Seq2Seq，机器翻译作为NLP领域中最重要的任务之一，2014出现的Seq2Seq模型，大幅提高了机器翻译的效果，从本质上来说，Seq2Seq就是提供了输入输出都是变长序列，且输入和输出序列的长度不等情况下的一种解决方案，Seq2Seq也一路进化，2015出现在NLP领域的注意力（Attention）机制，再次大幅提高Seq2Seq的效果。同时关于Attention机制有意思的是，2017年的Transformer是Self-Attention的集大成者，Transformer出现之后，Attention不仅在NLP领域大方光芒，同时席卷各大深度学习领域，甚至出现Attention+X的有趣现象，即万物皆可Attention，也算是近些年最成功的特征提取器了。</p>
<h2 id="4、强化学习领域"><a href="#4、强化学习领域" class="headerlink" title="4、强化学习领域"></a>4、强化学习领域</h2><p>接着再把目光转向AlphaGo所使用的技术，强化学习领域（Reinforcement Learning），如果问哪个领域最有可能实现通用人工智能，那么RL绝对是最优竞争力的一个答案。强化学习这个领域介绍起来要轻松很多，其并不像计算机视觉或是自然语言处理一样，包含各种各样的任务，研究人员多如牛毛，各种结构方法层出不穷，一眼望去令人头大，强化学习的主脉络要清晰简单很多，主要工作基本都是DeepMind的OpenAI以及少部分顶级高校实验室所贡献，也由DeepMind和OpenAI分别代表了强化学习的两大学派。</p>
<p>强化学习的历史可以追溯到很遥远的年代了，太过久远的历史我们就不去研究了，这里我们直接把目光聚焦到2013年把深度学习引入强化学习形成深度强化学习的开山之作《Playing atari with deep reinforcement learning》，也就是所谓的DQN网络结构，在介绍DQN网络结构之前，先简单介绍一下DQN之前的工作。</p>
<p>由于强化学习相关知识比较简单，我就先稍微讲一点，首先就是强化学习五元组了，（智能体，状态，动作，回报，策略），其实比较简单，就是对世界的一种抽象化，可以理解成一个人就是一个智能体，肚子饿了是一种状态，根据一般策略肚子饿了人就会去吃饭，去吃饭就是一种行为动作，肚子不饿了就是得到的回报。除此之外还有两个概念需要掌握，一个是Bellman方程，另一个是Markov决策过程，听起来玄乎，其实非常简单，第一个是指一个状态对应的价值Value是由当前状态根据策略做出动作得到的汇报，加上进行动作之后产生新状态对应的价值，这二者的和就代表当前状态的价值；第二个就是说t时刻的状态只与t-1时刻的状态有关，与t-1时刻之前的时刻都没有关系。基本就是这样，背景知识就介绍完了。</p>
<p>让我们回到主题，在2013年之前的强化学习是什么样呢？我们想要获得的是每种状态对应的价值，因为如果我们能求得每种状态的价值，在进行决策的时候，只需要选择所有可能达到的状态里价值最高的即可。以象棋为例，开局如果我们能知道挡门炮，跳马，拱卒，甚至直接炮换马这各种选择对应棋盘状态的价值，我们即可直接选择价值最大的走法，从而一步步往后走，直到最终获胜。那问题就转换成如何获得每种状态对应的价值呢？很简单，根据Bellman方程和Markou决策过程，我们只需要不停的进行迭代，直到获得所有状态的价值即可。还是以象棋为例，一开始所有棋盘状态对应的价值都是零，只有吃掉对方老将才能获得一个价值100的奖励回报，接着便可以根据Bellman公式不停迭代即可。这就是强化学习的思路，13年之前主要有两种强化学习算法，Q-learning和Sarsa，这里面的Q其实就是代指价值value，而Sarsa是State–action–reward–state–action的缩写，看两者代码的更新规则基本可以一眼看出区别，这里就不列了，本质上这些算法就是表格化的算法，及其直来直去，就是根据过去的状态统计迭代Q值。</p>
<p>时间来到2013年，DeepMind看到Q-learning算法的缺陷，最大的缺陷就是Q-learning并不具备预测能力，只有出现过的状态才能知道其Q值，因此Q-learning算法在遇到围棋，王者之类状态无穷无尽的问题时就傻眼了，于是DeepMind就说“我有一个天才的想法，那就是神经网络最近整天咋咋呼呼的，不就是靠着一手极强的预测回归能力吗，那我把神经网络和Q-learning一结合，岂不无敌！”DeepMind是对的，神经网络和Q-learning结合之后，出现了第一个深度强化学习算法DQN，一经推出，便风云骤起，深度强化学习的时代正式降临。</p>
<p>当然了，结合的过程中不可避免会遇到很多问题，DeepMind在论文中给出两大贡献，一个是对样本进行随机采样，另一个是设置两个网络，虽然两个网络一模一样，但是更新速度不同，从而使网络的训练更加稳定。顺着DQN这条路，后续又进行了一系列优化改进，提出了Double Q-Network，Prioritized replay Network，Dueling network，具体这里就不细讲了。</p>
<p>还记得上文提到DeepMind和OpenAI深度强化学习两大学派吗，两大学派最大的区别在于模型究竟是Value-based还是Policy-based，这里插一句虽然深度强化学习根据不同的特征可以分成Model-based和Model-free，On-Policy和Off-Policy等，就像上文的Q-learning和Sarsas就分别是Off_Policy和On-Policy的，不过Value-based和Policy-based的区分更重要一些。说到这里，你可能已经认识到DeepMind提出的DQN系列的思路都是Value-bades的，其实很简单Q所指代的就是Value，而Value-based和Policy-based的区别在于Value-based需要知道神经网络告知每种状态的价值，从而进行决定，Policy-based说“整啥花里胡哨的，神经网络你也别告诉我这些状态对应的价值，你只需要告诉我我该怎么做就行”。</p>
<p>这里开始谈谈OpenAI学派的贡献，2015年给出TRPO，2017给出PPO，都是Policy-based的解决方案。当然也并不是说DeepMind就一定不用Policy-based思想，比如在2015年给出的DDPG的思路就是把Value-based和Policy-based成功结合的典范，糅合和Value-based和Policy-based和优势，模型里直接出现4个神经网络，效果非常棒。除此之外还有一些其他的深度学习的强化方案像是A3C等，也是非常出名的模型。</p>
<p>强化学习思路不是很复杂，但是真正想要用好这些模型就需要很深的内功了，关于强化学习最新进展，几年2月份，OpenAI在Nature上放出了一篇名为《First return, then explore》的论文，论文一共46页，我没细看，大致思路是从如何更好设计奖励的分布，同时对智能体探索方向进行一些引导展开的，有兴趣的可以去仔细看看。</p>
<h2 id="5、生成领域"><a href="#5、生成领域" class="headerlink" title="5、生成领域"></a>5、生成领域</h2><p>接着聊一聊自己最近研究的比较多的生成领域，尽量简单谈一下，生成领域不像前面三个领域独立性高一些，其既有图像生成，也有文本生成，还有把强化学习引入生成领域的工作。生成领域生成哪些东西呢？写诗，写博客，写故事，画图，换脸，模拟画风，只有想不到，没有做不到，生成领域的应用太广泛了。</p>
<p>总结起来目前生成领域一共有四种主流模型，分别是GAN，VAE，Flow，Autogressive，Flow模型不是很了解就不讲了。剩下的三种的模型以GAN的思想最天马行空，最具想像空间，也是如今最热的一种模型；VAE模型最优雅，浑然天成，更具数学美感，最后的自回归Autogressive模型最传统，最简单。</p>
<p>这个领域必然要从GAN讲起，这个模型实在是太热门了，GitHub上有个仓库统计了比较知名的和GAN相关的工作，已经有3-400种，使得GAN前面加几个字母的名字已经被起光了，后来者再起名字越来越难，一不留神就和以前的工作撞名字了。GAN的起源一般认为是2014年Ian Goodfellow的一篇论文《Generative adversarial networks》，这篇论文提出的对抗思想实在令人着迷，又受到了深度学习三巨头之一的Yann LeCun的强推，于是一经发布便迅速流行起来。</p>
<p>然而GAN面临一系列的问题，容易模型崩溃，难以收敛，训练不动等，于是后续围绕GAN的工作两条线展开，一条是从基础架构上尝试解决GAN的固有问题，另一条是对GAN进行各种加工魔改应用到各大领域上。在解决GAN的困境这条路上，从GAN到WGAN，再到WGAN-GP，还有后来的Spectral Normalization，极大的改善了GAN面临的问题，至于细节就先不讲了；另一条线上出现了诸如DCGAN，CycleGAN，PGGAN，StyleGAN等一系列创新又有趣的工作，这里也不展开；想稍微谈一下另一个有趣和GAN相关的工作，是为了解决GAN在文本生成中面临的困境，即离散数据的问题，于是在2017年上交的Lantao Yu首次提出把深度强化学习引入到GAN里面，非常有意思，后续也有一系列的跟进。</p>
<p>再稍微讲一下VAE相关的工作，VAE全称变分自编码器，是在自编码器的基础上改进得来，VAE认为所有的数据都可以看做是很多正态分布变量的组合，于是不同于AE，VAE经过编码器之后会生成代表均值和方差对数的两列向量，接着使用重采样技术送入解码器，同时损失函数不仅有重构损失还引入了KL损失，从而保证模型的生成能力。在VAE之后，有一篇IntroVAE将GAN的思想和VAE的思想做了巧妙的结合，大幅提升了VAE的生成效果。即使如此VAE生成的结果依然距GAN有一定差距，后续又进化出了NVAE，VQ-VAE等，使得VAE的效果越来越好，相比GAN也毫不逊色。</p>
<h2 id="6、其他热门领域"><a href="#6、其他热门领域" class="headerlink" title="6、其他热门领域"></a>6、其他热门领域</h2><p>最后再提一些最近比较热，同时没那么主流的一些领域，这些领域我大都不是特别了解，所以只能稍微讲一下我的感受。像是图神经网络，知识图谱，元学习，AutoML，虽然热门，好像还没有什么特别令人震惊的成果；其次像是对比表示学习，迁移学习，多模态，小样本，其中迁移学习和小样本一直都挺热门的，而自监督领域的对比表示学习和将图像和文本进行融合的多模态从去年开始火起来，之所以大火和领域内出现了优秀的工作是分不开的，对比表示学习中Kaiming He提出的MoCo，以及Hinton组的Ting Chen提出了SIMCLR，大幅提高对比表示学习的性能（这两位大佬还都是华人，并且很年轻），在多模态领域出现的CLIP震惊了一众吃瓜群众，在前文提到的OpenAI发布的DALL-E就引进了CLIP的成果，再次证明了CLIP的强大，我所知道的目前比较前沿的领域就是这些了，应该已经基本囊括了现在比较热门的前沿领域。</p>
<p>天下大势，浩浩汤汤，顺之者昌，逆之者亡。深度学习第三次的浪潮走到今天，已经一次又一次证明了自己，而我们将亲自见证一个新时代的降临！</p>
<p>PS：最后的最后，讲一下自己第一次写作技术博客的感受。以前一直觉得应该找机会整理记录一下自己所学的知识，于是昨天趁闲着写下了本篇文章的标题，现在回看这个标题，属实有些大言不惭，题目太过宏大，写作的时候越写越是惶恐，不过最终还是硬着头皮写了下来。第一次技术写作，也算是练练手，现在回看本篇文章，问题一箩筐。说是科普文吧，又夹杂了太多了技术名词，说是技术文吧，大部分都是浅尝辄止，细节缘由都没能讲清楚，而且一篇纯文字的分享，没图没公式的，很多东西都没讲明白。不过第一次写作，不管怎样，总归是写完了，一开始真没想写这么多字，写到后面已经开始疯狂简化，能删则删，能不提就不提，即使如此写完一看居然有接近7000个字，其实还挺耗费精力的。最最后，还是希望自己能坚持下来，形成习惯，多写作一些技术文章，也算是给自己做个总结。</p>
</div><div class="tags"><a href="/tags/%E6%8A%80%E6%9C%AF/"><i class="fa fa-tag"></i>技术</a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><i class="fa fa-tag"></i>深度学习</a><a href="/tags/%E9%95%BF%E6%96%87/"><i class="fa fa-tag"></i>长文</a></div><div class="post-nav"><a class="pre" href="/2021/06/19/%E4%BD%BF%E7%94%A8Hexo%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">使用Hexo重新部署个人博客</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://eureke-ch.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E6%8A%80%E6%9C%AF/" style="font-size: 15px;">技术</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/GitHub-Pages/" style="font-size: 15px;">GitHub-Pages</a> <a href="/tags/%E5%8D%9A%E5%AE%A2/" style="font-size: 15px;">博客</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/tags/%E9%95%BF%E6%96%87/" style="font-size: 15px;">长文</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/07/05/Linux%E9%85%8D%E7%BD%AEIP%E5%92%8C%E8%AE%BE%E7%BD%AE%E7%BD%91%E5%8D%A1%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/">Linux配置IP和设置网卡工作模式</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/27/Python%E4%B8%AD%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%B0%83%E7%94%A8Python%E4%B8%AD%E7%9A%84%E5%87%BD%E6%95%B0/">Python中如何通过字符串调用Python中的函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/19/%E4%BD%BF%E7%94%A8Hexo%E9%87%8D%E6%96%B0%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">使用Hexo重新部署个人博客</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/18/%E7%AB%99%E5%9C%A82021%E5%B9%B4%E7%9A%84%E8%BF%99%E4%B8%AA%E8%8A%82%E7%82%B9%E4%B8%8A%EF%BC%8C%E5%9B%9E%E6%9C%9B%E8%BF%87%E5%8E%BB%E5%8D%81%E5%B9%B4%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%91%E5%B1%95/">站在2021年的这个节点上，回望过去十年深度学习的发展</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/Eureke-Ch" title="Github" target="_blank">Github</a><ul></ul><a href="https://leetcode-cn.com/u/eureke/" title="Leetcode" target="_blank">Leetcode</a><ul></ul><a href="https://www.kaggle.com/ygqodl" title="Kaggle" target="_blank">Kaggle</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">陈浩.</a> Powered by<a rel="nofollow" target="_blank" href="https://eureke-ch.github.io/"> Chenhao.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://eureke-ch.github.io/"> Ch.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>